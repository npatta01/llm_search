{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b9e0117-838c-4f94-a4f3-bd3335438451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.0.339\n",
      "  Downloading langchain-0.0.339-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting openai\n",
      "  Downloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing\n",
      "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pydantic==2.5.*\n",
      "  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting replicate==0.20.*\n",
      "  Downloading replicate-0.20.0-py3-none-any.whl (32 kB)\n",
      "Collecting SQLAlchemy==2.0.23\n",
      "  Downloading SQLAlchemy-2.0.23-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-generativeai==0.2.*\n",
      "  Downloading google_generativeai-0.2.2-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.9/dist-packages (from langchain==0.0.339) (2.28.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.9/dist-packages (from langchain==0.0.339) (5.4.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.9/dist-packages (from langchain==0.0.339) (3.8.3)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain==0.0.339) (1.23.4)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.9/dist-packages (from langchain==0.0.339) (3.6.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from langchain==0.0.339) (4.0.2)\n",
      "Collecting langsmith<0.1.0,>=0.0.63\n",
      "  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting pydantic-core==2.14.5\n",
      "  Downloading pydantic_core-2.14.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=4.6.1\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from replicate==0.20.*) (23.0)\n",
      "Collecting httpx<1,>=0.21.0\n",
      "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy==2.0.23) (2.0.1)\n",
      "Collecting google-api-core\n",
      "  Downloading google_api_core-2.14.0-py3-none-any.whl (122 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.2/122.2 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from google-generativeai==0.2.*) (4.64.1)\n",
      "Collecting google-ai-generativelanguage==0.3.3\n",
      "  Downloading google_ai_generativelanguage-0.3.3-py3-none-any.whl (267 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.9/267.9 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-auth in /usr/local/lib/python3.9/dist-packages (from google-generativeai==0.2.*) (2.16.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from google-generativeai==0.2.*) (3.19.6)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.0\n",
      "  Downloading proto_plus-1.22.3-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from openai) (1.3.0)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.339) (18.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.339) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.339) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.339) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.339) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.339) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<4.0->langchain==0.0.339) (2.8)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.21.0->replicate==0.20.*) (2019.11.28)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain==0.0.339) (1.26.14)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl (230 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.9/230.9 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth->google-generativeai==0.2.*) (4.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth->google-generativeai==0.2.*) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth->google-generativeai==0.2.*) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth->google-generativeai==0.2.*) (1.14.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core->google-generativeai==0.2.*) (1.51.1)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "  Downloading grpcio_status-1.59.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai==0.2.*) (0.4.8)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting grpcio<2.0dev,>=1.33.2\n",
      "  Downloading grpcio-1.59.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf\n",
      "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: typing\n",
      "  Building wheel for typing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26305 sha256=39952dac6fb8d8d9dbd4225ca986fd9d48573df286842530442b60fa0f3b65dc\n",
      "  Stored in directory: /root/.cache/pip/wheels/bf/97/61/e3c9316da01340cf1585f1f5a1c52d873f5023fb9f635385f2\n",
      "Successfully built typing\n",
      "Installing collected packages: typing-extensions, typing, tenacity, protobuf, mypy-extensions, marshmallow, jsonpointer, h11, grpcio, distro, annotated-types, typing-inspect, SQLAlchemy, pydantic-core, proto-plus, jsonpatch, httpcore, googleapis-common-protos, pydantic, httpx, grpcio-status, google-api-core, dataclasses-json, replicate, openai, langsmith, langchain, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: marshmallow\n",
      "    Found existing installation: marshmallow 2.21.0\n",
      "    Uninstalling marshmallow-2.21.0:\n",
      "      Successfully uninstalled marshmallow-2.21.0\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.51.1\n",
      "    Uninstalling grpcio-1.51.1:\n",
      "      Successfully uninstalled grpcio-1.51.1\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.41\n",
      "    Uninstalling SQLAlchemy-1.4.41:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.41\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.9.2\n",
      "    Uninstalling pydantic-1.9.2:\n",
      "      Successfully uninstalled pydantic-1.9.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "thinc 8.1.7 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.5.2 which is incompatible.\n",
      "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.1 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.1 which is incompatible.\n",
      "spacy 3.4.1 requires pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4, but you have pydantic 2.5.2 which is incompatible.\n",
      "gradient 2.0.6 requires marshmallow<3.0, but you have marshmallow 3.20.1 which is incompatible.\n",
      "confection 0.0.4 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.5.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed SQLAlchemy-2.0.23 annotated-types-0.6.0 dataclasses-json-0.6.3 distro-1.8.0 google-ai-generativelanguage-0.3.3 google-api-core-2.14.0 google-generativeai-0.2.2 googleapis-common-protos-1.61.0 grpcio-1.59.3 grpcio-status-1.59.3 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.339 langsmith-0.0.69 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.3.7 proto-plus-1.22.3 protobuf-4.25.1 pydantic-2.5.2 pydantic-core-2.14.5 replicate-0.20.0 tenacity-8.2.3 typing-3.7.4.3 typing-extensions-4.8.0 typing-inspect-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.0.339 openai typing pydantic==\"2.5.*\" replicate==0.20.* SQLAlchemy==2.0.23 google-generativeai==0.2.* --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb7c053a-c226-4012-bda6-14f7b0fa080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI, ChatGooglePalm\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "from langchain.llms import Replicate\n",
    "\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f570aa1-20ca-44ec-b086-90773fd94df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61246da7-53dd-4de9-93f5-bdc24d58ae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"r8_QpQZBY0Jc4rJDxfNt3CRqaJgAQIzfOP2frFLj\"\n",
    "os.environ[\"GOOGLE_PALM_API_KEY\"] = \"AIzaSyC80wytMV4McZgOIixiAK12sXcvhYOa96Y\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyC80wytMV4McZgOIixiAK12sXcvhYOa96Y\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f7a5d74-9eee-4562-91bb-9f2ef71a53c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CommaSeparatedListOutputParser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_parser \u001b[38;5;241m=\u001b[39m \u001b[43mCommaSeparatedListOutputParser\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CommaSeparatedListOutputParser' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1fbc23-4fc8-48f9-bfd4-ce8eb260055c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d50666c-dd66-4114-b778-baf4fae26067",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_openai = ChatOpenAI(model=\"gpt-4\")\n",
    "#llm_openai = OpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1be7114-e2c4-4ccd-8c8a-d8c7eba5448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Let's think step by step.\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d632c2f-51e8-4d05-aa9d-cc6fe3561cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Question: Can Barack Obama have a conversation with George Washington?\\n\\nLet's think step by step.\\n\\nAnswer: \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(question=\"Can Barack Obama have a conversation with George Washington?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083a314-d0ad-406a-ac8a-a976dd21143f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d73a80b3-5da8-42d7-bbdd-e2762a90d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_gpt4 = LLMChain(llm=llm_openai, prompt=prompt, output_parser=StrOutputParser())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0328bcf7-eba9-4687-a64f-fa5369c46557",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78420422-a3a9-41b5-843e-0007b8b3c24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\tCompletion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = chain_gpt4.run(question=\"Can Barack Obama have a conversation with George Washington?\")\n",
    "\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3f82f21-3d58-4caa-a44a-8b5fa85750f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, Barack Obama cannot have a conversation with George Washington because George Washington died in 1799, long before Barack Obama was born.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba32edc-0d0c-4b91-adf6-014a7f4016c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d23bacd-ac0d-425b-9e68-b9a1d4f6ab75",
   "metadata": {},
   "source": [
    "## Google Palm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fc89b37-c14e-45f2-be0f-20d45f325c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_palm = ChatGooglePalm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ade85b92-9585-4c3f-9831-47051aa44bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_palm = LLMChain(llm=llm_palm, prompt=prompt, output_parser=StrOutputParser())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e890ba1e-98ae-404b-b3c8-dd7eb0b7e46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Barack Obama and George Washington cannot have a conversation in the traditional sense, as they lived in different centuries and George Washington is deceased. However, it is possible for them to have a conversation in a fictional setting, such as a movie or a play. In such a setting, the two men could discuss their lives, their experiences, and their thoughts on the world. They could also share their hopes and dreams for the future. Such a conversation would be fascinating and thought-provoking, and it would provide us with a unique glimpse into the minds of two of the most important figures in American history.\\n\\nIn addition to a fictional setting, it is also possible for Barack Obama and George Washington to have a conversation in a virtual setting. For example, they could participate in a video chat or a virtual reality experience. In such a setting, the two men would be able to see and hear each other, and they would be able to interact in a more realistic way. This would allow them to have a more in-depth conversation about their lives and their experiences.\\n\\nWhile it is not possible for Barack Obama and George Washington to have a conversation in the traditional sense, it is possible for them to have a conversation in a fictional or virtual setting. Such a conversation would be fascinating and thought-provoking, and it would provide us with a unique glimpse into the minds of two of the most important figures in American history.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_palm.run(question=\"Can Barack Obama have a conversation with George Washington?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6454b34-8f47-4d9a-a54b-36110dba0c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99ef436f-a00b-488b-9751-97c42976c3b3",
   "metadata": {},
   "source": [
    "## Replicate\n",
    "\n",
    "https://python.langchain.com/docs/integrations/llms/replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b362a1-0143-4f6a-bbaf-1e7a4c085a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3815749a-83a1-4c0f-a0de-ab199e296883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f923d67-9f02-4c25-a1ef-222297c8dc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55da18ef-3cf9-4721-8499-0df751837e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "llm_llama7b = Replicate(\n",
    "    model=\"meta/llama-2-7b:77dde5d6c56598691b9008f7d123a18d98f40e4b4978f8a72215ebfc2553ddd8\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "llm_llama7b_chat = Replicate(\n",
    "    model=\"meta/llama-2-7b-chat:13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "llm_llama13b = Replicate(\n",
    "    model=\"meta/llama-2-13b:078d7a002387bd96d93b0302a4c03b3f15824b63104034bfa943c63a8f208c38\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "llm_llama13b_chat = Replicate(\n",
    "    model=\"meta/llama-2-13b-chat:f4e2de70d66816a838a89eeeb621910adffb0dd0baba3976c96980970978018d\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "llm_llama70b = Replicate(\n",
    "    model=\"meta/llama-2-70b:a52e56fee2269a78c9279800ec88898cecb6c8f1df22a6483132bea266648f00\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "llm_llama70b_chat = Replicate(\n",
    "    model=\"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9937f8de-3c37-49fb-8a81-8b622d320425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Replicate(verbose=True, model='meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3', replicate_api_token='r8_QpQZBY0Jc4rJDxfNt3CRqaJgAQIzfOP2frFLj')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48033df9-8800-4ef9-b5f8-98084c4da404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b34ff136-bb72-4e6b-805a-d9c5662607ed",
   "metadata": {},
   "source": [
    "## Llama 13b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "497023fb-ca0e-4e3b-b6f6-6d3f0d4cacc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1: Dogs do not have the physical ability to drive a car. They do not have opposable thumbs or the necessary physical strength to operate a vehicle.\\n\\nStep 2: Dogs also do not have the cognitive ability to understand the concepts of driving or operate a vehicle. They do not possess the necessary intelligence to comprehend the complex mechanics of a car.\\n\\nStep 3: Additionally, dogs cannot communicate effectively with humans to understand the instructions necessary to drive a car. They do not possess the language skills to understand and respond to verbal commands.\\n\\nConclusion: No, dogs cannot drive cars.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_llama13b_chat = Replicate(\n",
    "    model=\"a16z-infra/llama13b-v2-chat:df7690f1994d94e96ad9d568eac121aecf50684a0b0963b25a41cc40061269e5\",\n",
    "    model_kwargs={\"temperature\": 0.75, \"max_length\": 500, \"top_p\": 1},\n",
    "    verbose=True\n",
    ")\n",
    "prompt_other = \"\"\"\n",
    "User: Answer the following yes/no question by reasoning step by step. Can a dog drive a car?\n",
    "Assistant:\n",
    "\"\"\"\n",
    "llm_llama13b_chat(prompt_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de1a3b-dc15-43c7-bd3b-04e8e61c133f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd789d1b-e737-44e1-ba01-a256e1e5c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_llama13b = LLMChain(llm=llm_llama13b_chat, prompt=prompt, output_parser=StrOutputParser())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c34c80b-bb73-4f88-a75c-8d69c0fdeda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"🤔\\n\\nLet's start by considering the time period in which George Washington lived. He lived in the 18th century, during the American Revolution and the early years of the United States. Barack Obama, on the other hand, lived in the 21st century, long after Washington's time had passed.\\n\\n💡 Ah-ha! So, it's not possible for Barack Obama to have a conversation with George Washington because they lived in different time periods.\\n\\nNext, let's think about the fact that George Washington is a historical figure, and Barack Obama is a real person who lived in the present day. This means that George Washington is not alive anymore, and therefore cannot have a conversation with anyone, including Barack Obama.\\n\\n😕 Oh no! It looks like it's not possible for Barack Obama to have a conversation with George Washington after all.\\n\\nBut wait! 🤔 What if we could travel through time? Maybe there's a way for Barack Obama to travel back in time and have a conversation with George Washington after all! 😱\\nWhat do you think? Is it possible for Barack Obama to travel back in time and have a conversation with George Washington? 🤔\\nLet's keep thinking! 💡\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_llama13b.run(question=\"Can Barack Obama have a conversation with George Washington?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659dfce-8f4e-469a-9c1f-9175abe81291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37fbd0-3579-4182-a1bc-df79c845cdef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8317b2a0-04de-4cb7-bc2d-de923f4f09af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1e6b396-5d70-4f45-84ff-b600c6e8ff39",
   "metadata": {},
   "source": [
    "## Chat Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eac1a2-0dd7-45c1-997d-9f54c7f7fc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"2+2\", \"output\": \"4\"},\n",
    "    {\"input\": \"2+3\", \"output\": \"5\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83bfa9-8bf4-4396-9f07-789810004308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a prompt template used to format each individual example.\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3232d14-2ece-4334-b798-92b4e496de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b73480-e3ac-4cb7-acd6-41dedcadc73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( final_prompt.format(input= \"What's the square of a triangle?\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5618363-6064-4498-be05-9913217af7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = final_prompt | chain_gpt4\n",
    "\n",
    "chain.invoke({\"input\": \"What's the square of a triangle?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8811097c-2d9a-417c-aed9-296b6a4273eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c1949e-1fb6-44eb-b113-7a49abc48f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df66d8c3-7b9f-485d-8b1d-4d4fc9d6dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d8af431-97ed-4605-99fe-6af40b1613d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03203cb5-99a1-4444-8e14-222c68a59073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "30b15304-5fcb-4782-9f7c-47b4be93f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_zero_shot_template = \"\"\"\n",
    "You are an e-commerce shopping assistant. \n",
    "Given the title of a product, generate two possible user search queries. \n",
    "Ideally prioritize queries with tokens not in the product title \n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Input:   \n",
    "Title: {product_title}\n",
    "Output: \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "ecommerce_zero_shot_prompt = PromptTemplate(template=ecommerce_zero_shot_template, input_variables=[\"product_title\"],\n",
    "                                 partial_variables={\"format_instructions\": format_instructions}\n",
    "                                 )\n",
    "\n",
    "\n",
    "ecommerce_template = \"\"\"\n",
    "You are an e-commerce shopping assistant. \n",
    "Given the title of a product, generate two possible user search queries. \n",
    "Ideally prioritize queries with tokens not in the product title \n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Examples:   \n",
    "Input:   \n",
    "Title: Let's Find Pokémon! Special Complete Edition (2nd edition)   \n",
    "Output:    \n",
    "pokemon book pokedex   \n",
    "pokemon illustration book   \n",
    "Input:   \n",
    "Title: Keto Comfort Foods: Family Favorite Recipes Made Low-Carb and Healthy   \n",
    "Output:   \n",
    "soul food cookbook for beginners   \n",
    "chicken soup for nutrient \n",
    "\n",
    "Input:   \n",
    "Title: {product_title}\n",
    "Output: \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "ecommerce_prompt = PromptTemplate(template=ecommerce_template, input_variables=[\"product_title\"],\n",
    "                                 partial_variables={\"format_instructions\": format_instructions}\n",
    "                                 )\n",
    "\n",
    "\n",
    "\n",
    "ecommerce_sys_template = \"\"\"\n",
    "\n",
    "<s>[INST] <<SYS>> You are an e-commerce shopping assistant. <</SYS>>\n",
    "\n",
    "Given the title of a product, generate two possible user search queries. \n",
    "Ideally prioritize queries with tokens not in the product title. \n",
    "{format_instructions}\n",
    "\n",
    "Few shot Examples:   \n",
    "Input:   \n",
    "Title: Let's Find Pokémon! Special Complete Edition (2nd edition)   \n",
    "Output:    \n",
    "pokemon book pokedex   \n",
    "pokemon illustration book   \n",
    "Input:   \n",
    "Title: Keto Comfort Foods: Family Favorite Recipes Made Low-Carb and Healthy   \n",
    "Output:   \n",
    "soul food cookbook for beginners   \n",
    "chicken soup for nutrient \n",
    "\n",
    "Input:   \n",
    "Title: {product_title} \n",
    "Output: \n",
    "[/INST]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "ecommerce_prompt = PromptTemplate(template=ecommerce_template, input_variables=[\"product_title\"],\n",
    "                                 partial_variables={\"format_instructions\": format_instructions}\n",
    "                                 )\n",
    "\n",
    "\n",
    "ecommerce_sys_prompt = PromptTemplate(template=ecommerce_sys_template, input_variables=[\"product_title\"],\n",
    "                                 partial_variables={\"format_instructions\": format_instructions}\n",
    "                                 )\n",
    "sample_product_title = \"Biodegradable Bamboo Toothbrush, Natural Charcoal toothbrushes Soft Bristle Toothbrush Eco-Friendly Sustainable Toothbrush BPA Free Organic Compostable Travel Toothbrushes Wooden toothbrushes, 6 Pack\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a0db2dc-82e5-4304-a645-97bcf701cab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an e-commerce shopping assistant. \n",
      "Given the title of a product, generate two possible user search queries. \n",
      "Ideally prioritize queries with tokens not in the product title \n",
      "\n",
      "Your response should be a list of comma separated values, eg: `foo, bar, baz`\n",
      "\n",
      "Input:   \n",
      "Title: Biodegradable Bamboo Toothbrush, Natural Charcoal toothbrushes Soft Bristle Toothbrush Eco-Friendly Sustainable Toothbrush BPA Free Organic Compostable Travel Toothbrushes Wooden toothbrushes, 6 Pack\n",
      "Output: \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ( ecommerce_zero_shot_prompt.format(product_title = sample_product_title ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc1ac4-f943-4d4c-9062-4541c11b5bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "47a7fdf3-d1dd-4f12-91cf-550392630bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an e-commerce shopping assistant. \n",
      "Given the title of a product, generate two possible user search queries. \n",
      "Ideally prioritize queries with tokens not in the product title \n",
      "\n",
      "Your response should be a list of comma separated values, eg: `foo, bar, baz`\n",
      "\n",
      "Examples:   \n",
      "Input:   \n",
      "Title: Let's Find Pokémon! Special Complete Edition (2nd edition)   \n",
      "Output:    \n",
      "pokemon book pokedex   \n",
      "pokemon illustration book   \n",
      "Input:   \n",
      "Title: Keto Comfort Foods: Family Favorite Recipes Made Low-Carb and Healthy   \n",
      "Output:   \n",
      "soul food cookbook for beginners   \n",
      "chicken soup for nutrient \n",
      "\n",
      "Input:   \n",
      "Title: Biodegradable Bamboo Toothbrush, Natural Charcoal toothbrushes Soft Bristle Toothbrush Eco-Friendly Sustainable Toothbrush BPA Free Organic Compostable Travel Toothbrushes Wooden toothbrushes, 6 Pack\n",
      "Output: \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ( ecommerce_prompt.format(product_title = sample_product_title ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "41c04a97-e4a9-40a9-97e5-3084ef620a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>[INST] <<SYS>> You are an e-commerce shopping assistant. <</SYS>>\n",
      "\n",
      "Given the title of a product, generate two possible user search queries. \n",
      "Ideally prioritize queries with tokens not in the product title. \n",
      "Your response should be a list of comma separated values, eg: `foo, bar, baz`\n",
      "\n",
      "Few shot Examples:   \n",
      "Input:   \n",
      "Title: Let's Find Pokémon! Special Complete Edition (2nd edition)   \n",
      "Output:    \n",
      "pokemon book pokedex   \n",
      "pokemon illustration book   \n",
      "Input:   \n",
      "Title: Keto Comfort Foods: Family Favorite Recipes Made Low-Carb and Healthy   \n",
      "Output:   \n",
      "soul food cookbook for beginners   \n",
      "chicken soup for nutrient \n",
      "\n",
      "Input:   \n",
      "Title: Biodegradable Bamboo Toothbrush, Natural Charcoal toothbrushes Soft Bristle Toothbrush Eco-Friendly Sustainable Toothbrush BPA Free Organic Compostable Travel Toothbrushes Wooden toothbrushes, 6 Pack \n",
      "Output: \n",
      "[/INST]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ( ecommerce_sys_prompt.format(product_title = sample_product_title ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fc098d-e4e1-4a71-983f-6587f958b98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "744aa234-7fa5-4c0a-97a4-a8b4c1eb006c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eco friendly oral care products', 'sustainable dental hygiene items']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = ecommerce_prompt | llm_openai | output_parser\n",
    "\n",
    "chain.invoke({\"product_title\": sample_product_title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2e3d3421-6989-4833-a8e2-1e4f7e56fdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eco friendly dental care', 'compostable toothbrushes pack']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = ecommerce_zero_shot_prompt | llm_openai | output_parser\n",
    "\n",
    "chain.invoke({\"product_title\": sample_product_title})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a28e697-30a9-4e79-a280-9a1efd9b28a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89524070-6bdb-4dcf-b86b-49cab2a6a9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbadc14-c1cf-46b8-bbfb-e3efa707af64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0089e-1dd4-40ef-8078-cfd3165249b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "004675df-5f0a-4863-b2c3-061d47be4e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['product_title'], partial_variables={'format_instructions': 'Your response should be a list of comma separated values, eg: `foo, bar, baz`'}, template=\"\\nYou are an e-commerce shopping assistant. \\nGiven the title of a product, generate possible user search queries. \\nIdeally prioritize queries with tokens not in the product title \\n\\n{format_instructions}\\n\\nExamples:   \\nInput:   \\nTitle: Let's Find Pokémon! Special Complete Edition (2nd edition)   \\nOutput:    \\npokemon book pokedex   \\npokemon illustration book   \\nInput:   \\nTitle: Keto Comfort Foods: Family Favorite Recipes Made Low-Carb and Healthy   \\nOutput:   \\nsoul food cookbook for beginners   \\nchicken soup for nutrient \\n\\nInput:   \\nTitle: {product_title}\\nOutput: \\n\\n\\n\")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecommerce_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4aed3663-ed16-4479-9957-74c49f2314a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here are some possible user search queries for the product title \"Biodegradable Bamboo Toothbrush',\n",
       " 'Natural Charcoal toothbrushes Soft Bristle Toothbrush Eco-Friendly Sustainable Toothbrush BPA Free Organic Compostable Travel Toothbrushes Wooden toothbrushes',\n",
       " '6 Pack\":\\n\\n* bamboo toothbrush\\n* biodegradable toothbrush\\n* charcoal toothbrush\\n* eco-friendly toothbrush\\n* sustainable toothbrush\\n* BPA free toothbrush\\n* organic toothbrush\\n* compostable toothbrush\\n* travel toothbrush\\n* wooden toothbrush\\n* soft bristle toothbrush\\n* 6 pack toothbrush\\n\\nI have prioritized queries with tokens not in the product title',\n",
       " 'such as \"bamboo toothbrush\" and \"charcoal toothbrush\". I have also included queries that are more specific',\n",
       " 'such as \"eco-friendly toothbrush\" and \"sustainable toothbrush\". Finally',\n",
       " 'I have included queries that are more general',\n",
       " 'such as \"toothbrush\" and \"6 pack toothbrush\".']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = ecommerce_prompt | llm_palm | output_parser\n",
    "\n",
    "chain.invoke({\"product_title\": sample_product_title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc9a50-dbcb-497c-9daa-1e4905a837a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21364363-389e-4a51-870f-c6abc3a076f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Please note',\n",
       " 'the above examples are just that',\n",
       " 'examples',\n",
       " 'and are not meant to represent any specific product title or search queries.\\n\\n\\nPlease provide the possible search queries for the following product title:\\n\\nTitle: Super Soft & Fluffy Lightweight Womens Hoodie Sweatshirt with Pockets',\n",
       " 'Cute Cartoon Character Graphic (L',\n",
       " 'Black)']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = ecommerce_prompt | llm_llama13b_chat | output_parser\n",
    "\n",
    "chain.invoke({\"product_title\": sample_product_title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4e347ce-1742-4499-bbbe-cde809c95444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m     \n",
       "\u001b[0mllm_llama13b_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprompt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[List[str]]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Callbacks'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[List[str]]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[Dict[str, Any]]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Any'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m           Replicate\n",
       "\u001b[0;31mString form:\u001b[0m   \n",
       "\u001b[1mReplicate\u001b[0m\n",
       "Params: {'model': 'meta/llama-2-13b-chat:f4e2de70d66816a838a89eeeb621910adffb0dd0baba3976c96980970978018d', 'model_kwargs': {}}\n",
       "\u001b[0;31mFile:\u001b[0m           /usr/local/lib/python3.9/dist-packages/langchain/llms/replicate.py\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Replicate models.\n",
       "\n",
       "To use, you should have the ``replicate`` python package installed,\n",
       "and the environment variable ``REPLICATE_API_TOKEN`` set with your API token.\n",
       "You can find your token here: https://replicate.com/account\n",
       "\n",
       "The model param is required, but any other model parameters can also\n",
       "be passed in with the format model_kwargs={model_param: value, ...}\n",
       "\n",
       "Example:\n",
       "    .. code-block:: python\n",
       "\n",
       "        from langchain.llms import Replicate\n",
       "\n",
       "        replicate = Replicate(\n",
       "            model=(\n",
       "                \"stability-ai/stable-diffusion: \"\n",
       "                \"27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478\",\n",
       "            ),\n",
       "            model_kwargs={\"image_dimensions\": \"512x512\"}\n",
       "        )\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Create a new model by parsing and validating input data from keyword arguments.\n",
       "\n",
       "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
       "\u001b[0;31mCall docstring:\u001b[0m Check Cache and run the LLM on the given prompt and input.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?llm_llama13b_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8bab8b36-c8e4-42f7-8175-58e0e70692c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"##### Notes:\\n1. For any given input you may return up to two times more results than I ask for. If there is no output it will still count as correct but your score will be reduced by half because I didn't get exactly what I asked for.  \\n2. There are some edge cases where the title may not contain all the necessary information to generate valid search terms. In these instances\",\n",
       " \"if possible include the most common words from the product description along with a randomized phrase or word that fits within the context of the product. The goal here isn't so much about generating perfect search phrases,\"]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = ecommerce_prompt | llm_llama7b.bind( ) | output_parser\n",
    "\n",
    "chain.invoke({\"product_title\": sample_product_title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cce0cff7-ebd7-421f-bd0a-f09f4e94bb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Understood! Here are some possible user search queries for the given product titles:\\n\\nFor \"Let\\'s Find Pokémon! Special Complete Edition (2nd edition)\":\\n\\n* pokemon books for kids\\n* complete pokemon sets\\n* pokemon collector\\'s guide\\n* rare pokemon cards\\n\\nFor \"Keto Comfort Foods: Family Favorite Recipes Made Low-Carb and Healthy\":\\n\\n* low-carb cookbooks\\n* ketogenic recipe book\\n* comfort food healthy version\\n* paleo desserts']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = ecommerce_prompt | llm_llama7b_chat.bind( ) | output_parser\n",
    "\n",
    "chain.invoke({\"product_title\": sample_product_title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0260d883-c7f3-4444-9696-67ae4eb5ee19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['```python\\nimport re\\nfrom collections import Counter\\n\\n\\ndef get_tokens(title):\\n   \"\"\"\\n   Generate list of all words from input text\\n   :param str title: Title of the item\\n   :return: List of words\\n   \"\"\"\\n   return [word for word in re.findall(\\'[A-Za-z]\\'',\n",
       " 'title)]\\n\\n\\ndef compute_tfidf(words',\n",
       " 'ngram_len=3):\\n   \"\"\"\\n   Compute TFIDF score for each word based on frequency\\n   :param list words: List of']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = ecommerce_prompt | llm_llama13b.bind( ) | output_parser\n",
    "\n",
    "chain.invoke({\"product_title\": sample_product_title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "17351b10-421c-45be-913a-066ec366a0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sure',\n",
       " \"I'd be happy to help! Here are some possible user search queries based on the title you provided:\\n\\n* biodegradable toothbrushes\\n* natural charcoal toothbrushes\\n* soft bristle toothbrushes\\n* eco-friendly toothbrushes\\n* sustainable toothbrushes\\n* BPA free toothbrushes\\n* organic toothbrushes\\n* compostable toothbrushes\\n* wooden toothbrushes\\n* travel toothbrushes\"]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = ecommerce_prompt | llm_llama13b_chat.bind( ) | output_parser\n",
    "\n",
    "chain.invoke({\"product_title\": sample_product_title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0f0eed02-7146-4ed0-b0e9-5769331fa2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = ecommerce_prompt | llm_llama70b.bind() | output_parser\n",
    "\n",
    "chain.invoke({\"product_title\": sample_product_title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1fcdd6-acf7-4a4c-9aa7-2447be023cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3acf2b5-b60d-43fb-ad85-c3b5767c49fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "76e23587-eb7e-45fe-86f1-9f98ad7cfe9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sure! Here are two possible user search queries for the given product title:\\n\\n1. \"Eco-friendly toothbrushes\" - This query prioritizes the token \"eco-friendly\" which is not present in the product title',\n",
       " 'but is highly relevant to the product\\'s biodegradable and sustainable features.\\n2. \"Natural charcoal toothbrush\" - This query prioritizes the token \"natural charcoal\" which is also not present in the product title',\n",
       " \"but is a key feature of the product's bristles.\"]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = ecommerce_zero_shot_prompt | llm_llama70b_chat.bind() | output_parser\n",
    "\n",
    "chain.invoke({\"product_title\": sample_product_title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "121d7802-00bd-42ee-81f2-10d56d5a7d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sure',\n",
       " 'here are two possible user search queries for each product:\\n\\n1. Title: Let\\'s Find Pokémon! Special Complete Edition (2nd edition)\\n\\t* Search query 1: \"pokemon guide\"\\n\\t* Search query 2: \"illustrated pokemon encyclopedia\"\\n2. Title: Keto Comfort Foods: Family Favorite Recipes Made Low-Carb and Healthy\\n\\t* Search query 1: \"keto diet recipe book\"\\n\\t* Search query 2: \"low carb comfort food recipes']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = ecommerce_prompt | llm_llama70b_chat.bind() | output_parser\n",
    "\n",
    "chain.invoke({\"product_title\": sample_product_title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c19212-75d9-4016-9647-bc9254e44a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "09ba7bba-140b-4350-bd0b-c5649a972584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sure',\n",
       " 'here are some possible user search queries for the given product title:\\n\\n* Bamboo toothbrush\\n* Eco-friendly toothbrush\\n* Biodegradable toothbrush\\n* Natural charcoal toothbrush\\n* Sustainable toothbrush\\n* Organic toothbrush\\n* Compostable toothbrush\\n* Wooden toothbrush\\n* Travel toothbrush\\n* Six pack toothbrush\\n\\nThese queries prioritize tokens not in the product title',\n",
       " 'such as \"b']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = ecommerce_sys_prompt | llm_llama70b_chat.bind( ) | output_parser\n",
    "\n",
    "chain.invoke({\"product_title\": sample_product_title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f83d9-de28-4c24-b57b-492d77183b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb500fe5-2d85-4a13-a3a0-4b0d81c7501e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf678f0-9337-46f3-93c0-bbb7aa64da32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457b598-8914-4581-815e-f393df41a1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a184388-2c03-4601-8bfe-763751be8139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz`'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3be9bf-713a-4637-8fd5-ee9712a9fcb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aff22e-7382-4e63-89f6-41a5465e768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", f\"\"\"\"\n",
    "        You are an e-commerce shopping assistant. \n",
    "        Given the title of a product, generate possible user search queries. \n",
    "        Ideally prioritize queries with tokens not in the product title \n",
    "        Examples:   \n",
    "        Input:   \n",
    "        Title: Let's Find Pokémon! Special Complete Edition (2nd edition)   \n",
    "        Output:    \n",
    "        pokemon book pokedex   \n",
    "        pokemon illustration book   \n",
    "        Input:   \n",
    "        Title: Keto Comfort Foods: Family Favorite Recipes Made Low-Carb and Healthy   \n",
    "        Output:   \n",
    "        soul food cookbook for beginners   \n",
    "        chicken soup for nutrient \n",
    "        \"\"\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b801fe1-af28-428a-9800-dfd46e994d42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
