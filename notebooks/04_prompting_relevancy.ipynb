{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9rQ_DcfU4BdO",
    "outputId": "56845e44-5e05-4317-9780-f5019de63aad"
   },
   "outputs": [],
   "source": [
    "#!pip install langchain==0.0.339 openai typing pydantic==\"2.5.*\" replicate==0.20.* SQLAlchemy==2.0.23 google-generativeai==0.2.* --upgrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "In this notebook you will see how zero-shot and one-shot learning is used to assess relevancy of a product to a customer query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cNsq4XNK4Upj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI, ChatGooglePalm\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "from langchain.llms import Replicate\n",
    "\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from ipywidgets import interact\n",
    "import ipyplot\n",
    "import code.helper\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a_aMJdBf4Ur2"
   },
   "outputs": [],
   "source": [
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"../.env\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wpFWTXxA4UvO"
   },
   "outputs": [],
   "source": [
    "llm_openai = ChatOpenAI(model=\"gpt-4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "Zero shot prompt describes the task and provides query and item description\n",
    "\n",
    "One shot prompt provides example query-item description pairs besides the task and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HIlLK3C74obr"
   },
   "outputs": [],
   "source": [
    "zero_shot_template = \"\"\"\n",
    "You are an helpful e-commerce assistant.\n",
    "You will judge relevancy of an item to a query and respond one of the three options below.\n",
    "1. 'relevant' if the item is relevant to the query\n",
    "2. 'partially relevant' if the item is somewhat relevant to the query\n",
    "3. 'irrelevant' if the item is not relevant to the query\n",
    "\n",
    "query: {query}\n",
    "item: {item_description}\n",
    "\n",
    "Let's think step by step and explain your reasoning.\n",
    "Answer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_template = \"\"\"\n",
    "You are an helpful e-commerce assistant.\n",
    "You will judge relevancy of an item to a query and respond one of the three options below.\n",
    "1. 'relevant' if the item is relevant to the query\n",
    "2. 'partially relevant' if the item is somewhat relevant to the query\n",
    "3. 'irrelevant' if the item is not relevant to the query\n",
    "\n",
    "Here is an example of the task.\n",
    "one shot query: 30 oz tumbler with handle\n",
    "one shot item: Simple Modern 30 oz Tumbler with Handle and Straw Lid | Insulated Cup Reusable Stainless Steel Water Bottle Travel Cupholder Friendly | Gifts for Women Him Her | Trek Collection | 80s Mix\n",
    "Answer: relevant\n",
    "\n",
    "query: {query}\n",
    "item: {item_description}\n",
    "\n",
    "Let's think step by step and explain your reasoning.\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=zero_shot_template, input_variables=[\"query\", \"item_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1AO3OgXe4ohF"
   },
   "outputs": [],
   "source": [
    "chain_gpt4 = LLMChain(llm=llm_openai, prompt=prompt, output_parser=StrOutputParser())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iuWKqAC34ok-"
   },
   "outputs": [],
   "source": [
    "def get_relevancy(query, item):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = chain_gpt4.run(query=query,item_description=item)\n",
    "        print (result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "4fLnjjXN9jbN",
    "outputId": "39b3d3f5-a1dc-4124-c146-8da401edd6bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'relevant'\n",
      "\n",
      "The item is a men's shoe by Adidas, which matches the brand and gender specified in the query. It is also a size 15, which is what the query is looking for. Therefore, the item is relevant to the query.\n"
     ]
    }
   ],
   "source": [
    "query = \"adidas mens shoes 15\"\n",
    "item = \"adidas Originals Men's Superstar Foundation Shoes Sneaker, White/White/White, 15\"\n",
    "get_relevancy(query, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'partially relevant'\n",
      "\n",
      "The item is a men's shoe from Adidas which matches with the query. However, the size specified in the query is 15 but the item is of size 9. Hence, it's partially relevant since it fulfills two out of three criteria from the query.\n"
     ]
    }
   ],
   "source": [
    "query = \"adidas mens shoes 15\"\n",
    "item = \"adidas Ultraboost 19 Shoes Men's, White, Size 9\"\n",
    "get_relevancy(query, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'irrelevant'\n",
      "\n",
      "The query is requesting for adidas mens shoes in the size 15. The item listed is a women's Merrell hiking boot in the size 9. The brand, gender, shoe type, and size all do not match the search query, making it irrelevant to the user's needs.\n"
     ]
    }
   ],
   "source": [
    "query = \"adidas mens shoes 15\"\n",
    "item = \"Merrell Hiking Boots Womens', White, Size 9\"\n",
    "get_relevancy(query, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try a harder example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'irrelevant'\n",
      "\n",
      "Reasoning:\n",
      "The query is looking for gifts for men, but the item in question is a pair of women's hiking boots. Therefore, it is not relevant to the query.\n"
     ]
    }
   ],
   "source": [
    "query = \"gifts for men\"\n",
    "item = \"Merrell Hiking Boots Womens', White, Size 9\"\n",
    "get_relevancy(query, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'relevant'\n",
      "\n",
      "The item, a DualShock 4 Wireless Controller for PlayStation 4, can be considered as a relevant gift for men. PlayStation is a popular gaming console, and the controller is an integral part of the gaming experience. While it's not specific to men, it's not unusual for men to have an interest in video games. Therefore, this item can be seen as a potential gift for men.\n"
     ]
    }
   ],
   "source": [
    "query = \"gifts for men\"\n",
    "item = \"DualShock 4 Wireless Controller for PlayStation 4 - Glacier White\"\n",
    "get_relevancy(query, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'irrelevant'\n",
      "\n",
      "Reasoning:\n",
      "The query is for 'gifts for men'. The item is a pack of insulin syringes, which is a medical supply, not typically given as a gift. Furthermore, the item does not specify anything to suggest it is particularly suitable or designed for men. Therefore, it is not relevant to the query.\n"
     ]
    }
   ],
   "source": [
    "query= \"gifts for men\"\n",
    "item=\"\"\"Brandzig U-40 Pet Insulin Syringes 29G 3/10cc, 1/2\" 100-Pack\"\"\"\n",
    "get_relevancy(query, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
